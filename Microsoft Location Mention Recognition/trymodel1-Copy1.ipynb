{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27ad31bd-2a69-4b7d-acd6-280f19c237cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import BertForTokenClassification,BertTokenizerFast,pipeline\n",
    "import jiwer\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from jiwer import wer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d05a3818-9abd-4ee4-93e6-e58241a844cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForTokenClassification.from_pretrained('./results')\n",
    "tokenizer = BertTokenizerFast.from_pretrained('./results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa8051af-07b6-42e7-a67b-56e3d37828c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<transformers.pipelines.token_classification.TokenClassificationPipeline at 0x1bd87cb9f70>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_checkpoint='./results'\n",
    "\n",
    "token_classifier = pipeline(\n",
    "    \"token-classification\", model=model_checkpoint, aggregation_strategy=\"simple\")\n",
    "\n",
    "token_classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a519a5f5-791e-4088-8bf7-c3801c07dd6c",
   "metadata": {},
   "source": [
    "## defining functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d847e8d4-e97d-410f-9fc7-da1dc9aa76d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(sentences, token_classifier):\n",
    "    pred_texts = [] \n",
    "    \n",
    "    for sentence in tqdm(sentences, desc=\"Processing sentences\"):\n",
    "        ner_results = token_classifier(sentence)  \n",
    "        sorted_entities = sorted([entity['word'] for entity in ner_results])\n",
    "        grouped_entities = []\n",
    "        current_entity = \"\"\n",
    "        for i, word in enumerate(sorted_entities):\n",
    "            if i > 0 and word.istitle() and current_entity:  # If the word starts a new entity\n",
    "                grouped_entities.append(current_entity.strip())  # Add the current entity to the list\n",
    "                current_entity = word  # Start a new entity\n",
    "            else:\n",
    "                current_entity += f\" {word}\"\n",
    "        if current_entity: \n",
    "            grouped_entities.append(current_entity.strip())\n",
    "        \n",
    "        # Join each entity into a comma-separated string\n",
    "        pred_texts_1 = \", \".join(grouped_entities)\n",
    "        pred_texts.append(pred_texts_1)\n",
    "    \n",
    "    return pred_texts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e1cf64b-ef35-48f4-bf32-a406117ba700",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_wer(predicted_texts, reference_texts):\n",
    "    wer_score = wer(reference_texts, predicted_texts)\n",
    "    return wer_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3bf572e-3a95-4858-b06e-1b202bcf978f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = re.sub(r'@', '', text)\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s,]','', text)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b617469-dde5-45b9-ab0c-0931b1bee0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(r'\\s*##\\s*', '', text)\n",
    "    text = re.sub(r'\\s*\\.\\s*', '.', text)\n",
    "    text = re.sub(r'^(a|at|be|s|u)\\s+', '', text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r'\\b(MaheshBabu)\\b', '', text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r'\\b(MONSTA)\\b', '', text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r'\\b(ososscate)\\b', '', text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', '', text)\n",
    "    text = re.sub(r'\\b\\w*(Fires|Floods|Earthquakes)\\w*\\b', '', text, flags=re.IGNORECASE)\n",
    "    text = ' '.join(text.split())\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63603552-e728-4bc4-8982-42a998b5fad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_locations(location_string):\n",
    "    locations = [loc.strip() for loc in location_string.split(',')]\n",
    "    seen = set()\n",
    "    unique_locations = []\n",
    "    for loc in locations:\n",
    "        if loc not in seen:\n",
    "            unique_locations.append(loc)\n",
    "            seen.add(loc)\n",
    "    \n",
    "    return unique_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "431aebd6-4a5d-4357-b911-0a401667ee40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_and_combine(locations_list):\n",
    "    combined_strings = []\n",
    "    \n",
    "    for sublist in locations_list:\n",
    "        combined_string = \" \".join(sublist)\n",
    "        combined_strings.append(combined_string)\n",
    "    \n",
    "    return combined_strings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe7c7f8-b1af-430b-aa4e-7e078db51870",
   "metadata": {},
   "source": [
    "## Inference and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d8af08a-9679-40be-9f06-2836c37186f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_1001136212718088192</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EllicottCity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_1001136696589631488</td>\n",
       "      <td>Flash floods struck a Maryland city on Sunday,...</td>\n",
       "      <td>Maryland</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 tweet_id                                               text  \\\n",
       "0  ID_1001136212718088192                                                NaN   \n",
       "1  ID_1001136696589631488  Flash floods struck a Maryland city on Sunday,...   \n",
       "\n",
       "       location  \n",
       "0  EllicottCity  \n",
       "1      Maryland  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('Train_1.csv')\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "808c25ca-b7bc-47ad-9158-176e707b329c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=data.dropna(subset=['text','location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a315095b-ff18-446e-82b0-bc571ee4a06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1=data1.text.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb8ea8b9-1090-425e-bbbd-9a51bc9a47c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Flash floods struck a Maryland city on Sunday, washing out streets and tossing cars like bath toys.',\n",
       " 'State of emergency declared for Maryland flooding:  via @YouTube']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e27d164-b96e-498a-8831-a14c7e0af870",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text2 = [preprocess_text(text) for text in text1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d11ff2d3-ced1-4042-8561-7ba138a410d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Flash floods struck a Maryland city on Sunday, washing out streets and tossing cars like bath toys',\n",
       " 'State of emergency declared for Maryland flooding  via YouTube']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a06ee073-4962-4029-a228-5ad77582c6d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sentences: 100%|███████████████████████████████████████████████████████████████████| 11849/11849 [32:36<00:00,  6.06it/s]\n"
     ]
    }
   ],
   "source": [
    "text3 = infer(text2,token_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e652eac1-a350-48e9-a672-36f03b9748b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_pred_texts = [clean_text(text) for text in text3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c39d2b43-861a-442e-a962-b101544afb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean_pred_texts[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fed48ef0-d9a8-4dd0-99de-50495634f23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_locations = [clean_locations(loc) for loc in clean_pred_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb61f62d-ae2f-4613-8a96-f6ad20c00927",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaned_locations[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f3b0933f-7e62-479c-b640-5d8de836ebae",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_preds = flatten_and_combine(cleaned_locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eadce3bf-93e2-4db2-8c61-cc177f5a4984",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean_preds[5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "50c2a816-59a9-4c52-82bc-000885caabe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_texts=data1.location.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f8addfcb-5889-4e95-89e7-c5058348bb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#true_texts[5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a2870cbd-a0e1-42a8-a1ea-b291deeaca1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11696658097686376"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_wer(clean_preds,true_texts)\n",
    "#0.10355546766857821 #0.08552501483092742"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0a1c6696-7534-4b3c-8629-417470f6fc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_csv=pd.read_csv('Test.csv')\n",
    "test_text=test_csv.text.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7f530554-5cee-4462-a871-ae2fc5a62235",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text2 = [preprocess_text(text) for text in test_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "86870e4e-0d21-48c8-803f-38db5708d706",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sentences: 100%|█████████████████████████████████████████████████████████████████████| 2942/2942 [08:01<00:00,  6.11it/s]\n"
     ]
    }
   ],
   "source": [
    "pred_texts = infer(test_text2, token_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c26a2524-155e-4897-82e3-0f313a822df0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['New England, New Orleans', 'MARYLAND', 'Ellicott City, Maryland']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_texts[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "59ee7fa9-63de-4e5a-8b4f-5724c3a6a155",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_pred_texts = [clean_text(text) for text in pred_texts]\n",
    "clean_pred_texts = ['nan' if loc == '' else loc for loc in clean_pred_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6b34a6ac-f265-4629-a6da-629138b14a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_locations = [clean_locations(loc) for loc in clean_pred_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c3f21f34-e911-49ef-bf3c-55c184f0f022",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_preds = flatten_and_combine(cleaned_locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ec7a0d30-60a4-493d-8565-402150f6c644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2942"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clean_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fcd5e158-0f98-4b1b-b31a-31249354d86f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['New England New Orleans',\n",
       " 'MARYLAND',\n",
       " 'Ellicott City Maryland',\n",
       " 'Ellicott City Maryland Md',\n",
       " 'Ellicott City Maryland']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_preds[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fab7af89-80d4-490d-957b-3877e1344171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2937</th>\n",
       "      <td>ID_915017703055749120</td>\n",
       "      <td>Mexico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2938</th>\n",
       "      <td>ID_915026957758328832</td>\n",
       "      <td>Las Vegas Mexico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2939</th>\n",
       "      <td>ID_915253441726889984</td>\n",
       "      <td>Calgary Mexico City</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2940</th>\n",
       "      <td>ID_915971980859400192</td>\n",
       "      <td>Chiapas Mexicos Oaxaca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2941</th>\n",
       "      <td>ID_916099144116191232</td>\n",
       "      <td>Mexico</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   tweet_id                location\n",
       "2937  ID_915017703055749120                  Mexico\n",
       "2938  ID_915026957758328832        Las Vegas Mexico\n",
       "2939  ID_915253441726889984     Calgary Mexico City\n",
       "2940  ID_915971980859400192  Chiapas Mexicos Oaxaca\n",
       "2941  ID_916099144116191232                  Mexico"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame({\n",
    "    'tweet_id': test_csv['tweet_id'],\n",
    "    'location': clean_preds\n",
    "})\n",
    "\n",
    "results_df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6f4a309e-3737-4f3f-afd1-a3335877e0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'test_submission3.csv'\n",
    "results_df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f71e24-b621-46c1-b356-d5ade6c6938d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3bb9e4-8047-4b30-b9c1-5142eac90979",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
